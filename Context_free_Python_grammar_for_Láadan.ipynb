{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMdBM2/GhQCEOkOCQciFWP2"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Контекстно-свободная грамматика для языка [Láadan](https://en.wikipedia.org/wiki/L%C3%A1adan)\n",
        "Правила:\n",
        "```\n",
        "start: sentence\n",
        "sentence: verb_phrase subject_phrase object_phrase? EVIDENCE_PARTICLE? EOS\n",
        "\n",
        "verb_phrase: SPEECH_ACT_PARTICLE? TENSE_PARTICLE verb_form\n",
        "verb_form: \"me\"? VERB\n",
        "subject_phrase : NOUN | pronoun_marked | adjective_phrase\n",
        "adjective_phrase: \"wo\" NOUN \"wo\" ADJ\n",
        "pronoun_marked: PRONOUN_STEM \"e\" | \"a\" | \"i\"\n",
        "object_phrase: NOUN \"th\"\n",
        "\n",
        "EOS: \".\" | \"!\" | \"?\"\n",
        "SPEECH_ACT_PARTICLE: \"bíi\" | \"báa\" | \"bó\" | \"bóo\" | \"bé\" | \"bée\"\n",
        "TENSE_PARTICLE: \"ril\" | \"eril\" | \"aril\"\n",
        "EVIDENCE_PARTICLE: \"wa\" | \"wi\" | \"we\" | \"wáa\" | \"waá\" | \"wo\" | \"wóo\"\n",
        "\n",
        "NOUN: \"bo\" | \"doyu\" | \"edan\" | \"rul\"| \"with\" | \"yu\"\n",
        "VERB: \"áya\" | \"thi\" | \"yod\" | \"úuya\"\n",
        "ADJ: \"áya\"\n",
        "PRONOUN_STEM: \"l\" | \"n\" | \"b\"\n",
        "\n",
        "%import common.WS\n",
        "%ignore /([wo]?<!) /\n",
        "%ignore WS\n",
        "\n",
        "```\n",
        "\n",
        "Лаадан-английский словарь словарь:\n",
        "* Speech-act particles:\n",
        " * `bíi`: declarative sentence\n",
        " * `báa`: interrogative sentence\n",
        " * `bó`: imperative sentence\n",
        " * `bóo`: request sentence\n",
        " * `bé`: promisse sentence\n",
        " * `bée`: warning sentence\n",
        "* Tense particles:\n",
        " * `ril`: present\n",
        " * `eril`: past\n",
        " * `aril`: future\n",
        "* Evidential particles:\n",
        " * `wa`: known to speaker because perceived by speaker, externally or internally\n",
        " * `wi`: known to speaker because self-evident\n",
        " * `we`: perceived by speaker in a dream\n",
        " * `wáa`: assumed true by speaker because speaker trusts source\n",
        " * `waá`: assumed false by speaker because speaker distrusts source; if evil intent by the source is also assumed\n",
        " * `wo`: imagined or invented by speaker, hypothetical\n",
        " * `wóo`: used to indicate that the speaker states a total lack of knowledge as to the validity of the matter\n",
        "* Content words:\n",
        " * `bo`: mountain\n",
        " * `doyu`: apple\n",
        " * `edan`: linguistics\n",
        " * `rul`: cat\n",
        " * `with`: human, woman\n",
        " * `yu`: fruit\n",
        "* Functional words:\n",
        " * `a`: to love an inanimate object, love for it\n",
        " * `áya`: beautiful, to be beautiful\n",
        " * `thi`: to habe\n",
        " * `yod`: to eat\n",
        "  * `úuya`: to hurt, to feel pain\n",
        "* Pronouns:\n",
        " * к местоимениям **обязательно** прибавляется гласная `e/i/a`: `e`: немаркированно, `a`: о любимом человеке, `i`: об уважаемом человеке\n",
        " * `l-` : I\n",
        " * `n-`: you\n",
        " * `b-`: (s)he"
      ],
      "metadata": {
        "id": "J7mmqjrFx2DX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install lark anytree"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_RjX0NBvdsY9",
        "outputId": "77fb0062-3361-4c73-a581-952e23b7a3cb"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting lark\n",
            "  Downloading lark-1.2.2-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting anytree\n",
            "  Downloading anytree-2.13.0-py3-none-any.whl.metadata (8.0 kB)\n",
            "Downloading lark-1.2.2-py3-none-any.whl (111 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m111.0/111.0 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading anytree-2.13.0-py3-none-any.whl (45 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.1/45.1 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: lark, anytree\n",
            "Successfully installed anytree-2.13.0 lark-1.2.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from lark import Lark, Tree, Token, Transformer, Visitor\n",
        "\n",
        "from anytree import Node, RenderTree, find_by_attr"
      ],
      "metadata": {
        "id": "vXef9PqTsP2g"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "laadan_grammar = \"\"\"\n",
        "start: sentence\n",
        "sentence: verb_phrase subject_phrase object_phrase? EVIDENCE_PARTICLE? EOS\n",
        "\n",
        "verb_phrase: SPEECH_ACT_PARTICLE? TENSE_PARTICLE verb_form\n",
        "verb_form: \"me\"? VERB\n",
        "subject_phrase : NOUN | pronoun_marked | adjective_phrase\n",
        "adjective_phrase: \"wo\" NOUN \"wo\" ADJ\n",
        "pronoun_marked: PRONOUN_STEM + PRONOUN_MARKER\n",
        "object_phrase: NOUN \"th\"\n",
        "\n",
        "EOS: \".\" | \"!\" | \"?\"\n",
        "SPEECH_ACT_PARTICLE: \"bíi\" | \"báa\" | \"bó\" | \"bóo\" | \"bé\" | \"bée\"\n",
        "TENSE_PARTICLE: \"ril\" | \"eril\" | \"aril\"\n",
        "EVIDENCE_PARTICLE: \"wa\" | \"wi\" | \"we\" | \"wáa\" | \"waá\" | \"wo\" | \"wóo\"\n",
        "\n",
        "NOUN: \"bo\" | \"doyu\" | \"edan\" | \"rul\"| \"with\" | \"yu\"\n",
        "VERB: \"áya\" | \"thi\" | \"yod\" | \"úuya\"\n",
        "ADJ: \"áya\"\n",
        "PRONOUN_STEM: \"l\" | \"n\" | \"b\"\n",
        "PRONOUN_MARKER: \"e\" | \"a\" | \"i\"\n",
        "\n",
        "%import common.WS\n",
        "%ignore /([wo]?<!) /\n",
        "%ignore WS\n",
        "\"\"\"\n",
        "\n",
        "laadan_parser = Lark(laadan_grammar, start='start')"
      ],
      "metadata": {
        "id": "ae8PSb4QIJCn"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sent = \"bíi eril yod le doyuth wa.\" # я съела яблоко\n",
        "tree = laadan_parser.parse(sent)\n",
        "print(tree.pretty())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XXG9dlk9mZQQ",
        "outputId": "b52e88cc-8bf4-451c-f354-faab0ce25934"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "start\n",
            "  sentence\n",
            "    verb_phrase\n",
            "      bíi\n",
            "      eril\n",
            "      verb_form\tyod\n",
            "    subject_phrase\n",
            "      pronoun_marked\n",
            "        l\n",
            "        e\n",
            "    object_phrase\tdoyu\n",
            "    wa\n",
            "    .\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Дерево"
      ],
      "metadata": {
        "id": "iDi3DS80ngYr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def tree_to_anytree(lark_node, parent=None):\n",
        "    if isinstance(lark_node, Tree):\n",
        "        node = Node(lark_node.data, parent=parent)\n",
        "        for child in lark_node.children:\n",
        "            tree_to_anytree(child, parent=node)\n",
        "        return node\n",
        "    elif isinstance(lark_node, Token):\n",
        "        return Node(f\"{lark_node.type}: {lark_node.value}\", parent=parent)\n",
        "\n",
        "anytree_root = tree_to_anytree(laadan_parser.parse(\"bíi eril yod le doyuth wa.\"))\n",
        "for pre, _, node in RenderTree(anytree_root):\n",
        "    print(f\"{pre}{node.name}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aeucKaIprdNS",
        "outputId": "a003e042-9b6a-4369-9794-4b304c67ccbd"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "start\n",
            "└── sentence\n",
            "    ├── verb_phrase\n",
            "    │   ├── SPEECH_ACT_PARTICLE: bíi\n",
            "    │   ├── TENSE_PARTICLE: eril\n",
            "    │   └── verb_form\n",
            "    │       └── VERB: yod\n",
            "    ├── subject_phrase\n",
            "    │   └── pronoun_marked\n",
            "    │       ├── PRONOUN_STEM: l\n",
            "    │       └── PRONOUN_MARKER: e\n",
            "    ├── object_phrase\n",
            "    │   └── NOUN: doyu\n",
            "    ├── EVIDENCE_PARTICLE: wa\n",
            "    └── EOS: .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Переводчик на псевдоанглийский"
      ],
      "metadata": {
        "id": "TX9HIWEx7fFS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def translate_pronoun(s: str):\n",
        "    dictionary = {\n",
        "        \"l\":\"I\",\n",
        "        \"n\": \"you\",\n",
        "        \"b\": \"she\",\n",
        "\n",
        "        \"e\": \"\",\n",
        "        \"a\": \"beloved\",\n",
        "        \"i\": \"honored\"}\n",
        "    return dictionary[s]\n",
        "\n",
        "def translate(s: str):\n",
        "    dictionary = {\n",
        "        \"bo\": \"mountain\",\n",
        "        \"doyu\": \"apple\",\n",
        "        \"edan\": \"linguistics\",\n",
        "        \"rul\": \"cat\",\n",
        "        \"with\": \"woman\",\n",
        "        \"yu\": \"fruit\",\n",
        "\n",
        "        \"a\": \"love\",\n",
        "        \"áya\": \"beautiful\",\n",
        "        \"thi\": \"have\",\n",
        "        \"yod\": \"eat\",\n",
        "        \"úuya\": \"hurt\",\n",
        "\n",
        "        \"wa\": \"as I perceive\",\n",
        "        \"we\": \"in my dream\",\n",
        "        \"wáa\": \"as trusted sources say\",\n",
        "        \"waá\": \"though untrusted sources claim\",\n",
        "        \"wo\": \"in this hypothetical scenario\",\n",
        "        \"wóo\": \"with unknown validity\"\n",
        "    }\n",
        "    return dictionary[s]\n",
        "\n",
        "def starke_verben_zu_praeteritum(verb):\n",
        "    starke = {'eat': 'ate',\n",
        "              'hurt': 'hurt',\n",
        "              'have': 'had'}\n",
        "    try:\n",
        "        return starke[verb]\n",
        "    except KeyError:\n",
        "        return None\n",
        "\n",
        "\n",
        "class SimpleTranslator(Visitor):\n",
        "    def __init__(self):\n",
        "        self.subject = None\n",
        "        self.verb = None\n",
        "        self.obj = None\n",
        "        self.tense = None\n",
        "        self.act = None\n",
        "        self.evidential = None\n",
        "        self.eos = None\n",
        "        self.pronoun = None\n",
        "\n",
        "\n",
        "    def __default__(self, node):\n",
        "        if node.data == \"object_phrase\":\n",
        "            self.obj = translate(node.children[0].value)\n",
        "        elif node.data == \"subject_phrase\":\n",
        "            n = node.children[0]\n",
        "            if isinstance(n, Token):\n",
        "                self.subject = translate(n.value)\n",
        "            elif n.data == \"pronoun_marked\":\n",
        "                self.subject = translate_pronoun(n.children[1].value) + \" \" + translate_pronoun(n.children[0].value)\n",
        "            elif n.data == \"adjective_phrase\":\n",
        "                self.subject = translate(n.children[1].value) + \" \" + translate(n.children[0].value)\n",
        "        elif node.data == \"verb_phrase\":\n",
        "            for n in node.children:\n",
        "                if isinstance(n, Token) and n.type == \"SPEECH_ACT_PARTICLE\":\n",
        "                    self.act = n.value\n",
        "                elif isinstance(n, Token) and n.type == \"TENSE_PARTICLE\":\n",
        "                    self.tense = n.value\n",
        "                elif isinstance(n, Tree) and n.data == \"verb_form\":\n",
        "                    self.verb = translate(n.children[0].value)\n",
        "        elif node.data == \"sentence\":\n",
        "            for n in node.children:\n",
        "                if isinstance(n, Token) and n.type == \"EOS\":\n",
        "                    self.eos = n.value\n",
        "                elif isinstance(n, Token) and n.type == \"EVIDENCE_PARTICLE\":\n",
        "                    self.evidential = n.value\n",
        "\n",
        "    def get_result(self):\n",
        "        # print(self.obj, self.subject, self.verb, self.tense, self.act, self.eos)\n",
        "        leading_group = self.subject + \" \" + self.verb\n",
        "        if self.tense == \"eril\" and self.act != \"báa\":\n",
        "            leading_group = self.subject + \" \" + starke_verben_zu_praeteritum(self.verb)\n",
        "\n",
        "        # tense and act\n",
        "        if self.tense == \"ril\" and self.act == \"báa\":\n",
        "            leading_group = \"Do \" + leading_group\n",
        "        elif self.tense == \"eril\" and self.act == \"báa\":\n",
        "            leading_group = \"Did \" + leading_group\n",
        "        elif self.tense == \"eril\" and self.act != \"báa\":\n",
        "            praeteritum = starke_verben_zu_praeteritum(self.verb)\n",
        "            if praeteritum == None:\n",
        "                leading_group = leading_group+\"d\"\n",
        "        elif self.tense == \"aril\" and self.act == \"báa\":\n",
        "            leading_group = \"Will \" + leading_group\n",
        "        elif self.tense == \"aril\" and self.act != \"báa\":\n",
        "            leading_group = self.subject + \" will \" + self.verb\n",
        "\n",
        "        leading_group = translate(self.evidential) + \" \" + leading_group\n",
        "\n",
        "\n",
        "        return leading_group+(\" \"+self.obj if self.obj != None else \"\")+self.eos"
      ],
      "metadata": {
        "id": "RzwVsZPkzJPh"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentence_tree = laadan_parser.parse(\"bíi eril yod la doyuth we.\")\n",
        "tr = SimpleTranslator()\n",
        "tr.visit(sentence_tree)\n",
        "print(tr.get_result())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T5dgx_9CC3zX",
        "outputId": "d3ef98a5-1a25-4597-d38c-f830442bbf6e"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "in my dream beloved I ate apple.\n"
          ]
        }
      ]
    }
  ]
}